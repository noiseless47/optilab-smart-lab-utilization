# CFRS TimescaleDB Statistical Layer
## Research-Grade Database Architecture for Composite Fault Risk Score

---

## ðŸŽ¯ Executive Summary

This document describes the **TimescaleDB statistical layer** that exposes derivative inputs for the **Composite Fault Risk Score (CFRS)** system in academic computer lab environments.

**Key Design Principle:** The database provides **statistically correct raw derivatives** only. No thresholds, no ML models, no scoring logic exists in SQL.

---

## ðŸ“ Design Philosophy

### Core Principles

1. **Raw Data Immutability** - Metrics table is append-only
2. **Statistical Interpretability** - All aggregates are reproducible and auditable
3. **No Policy Decisions in Schema** - No hardcoded thresholds or classifications
4. **Research-Grade Quality** - Suitable for IEEE peer review and patent filing
5. **Institution-Scale Deployment** - Handles 1000+ systems with 5-minute sampling

### Why No CFRS Computation in Database?

- **Flexibility** - Research algorithms evolve; SQL schemas don't
- **Auditability** - CFRS logic in application code is easier to review
- **Performance** - Complex ML/statistical models don't belong in OLTP systems
- **Separation of Concerns** - Database = storage/aggregation, Application = intelligence

---

## ðŸ§± CFRS Component Breakdown

CFRS requires three statistical components:

### 1ï¸âƒ£ Deviation (D)
**Purpose:** Measure how far current behavior deviates from expected baseline

**Database Provides:**
- Baseline statistics per system/metric (mean, stddev, median)
- Current hour/day averages

**External CFRS Engine Computes:**
```
z-score = (current_value - baseline_mean) / baseline_stddev
MAD-score = |current_value - baseline_median| / MAD
```

### 2ï¸âƒ£ Variance (V)
**Purpose:** Measure instability/volatility in system behavior

**Database Provides:**
- STDDEV for each metric per hour/day
- P95 percentiles for dispersion context

**External CFRS Engine Computes:**
```
variance_score = normalized(current_stddev)
volatility_index = stddev / mean  (coefficient of variation)
```

### 3ï¸âƒ£ Trend (S)
**Purpose:** Detect degradation patterns over time

**Database Provides:**
- Daily averages with epoch timestamps
- Multi-day rolling aggregates

**External CFRS Engine Computes:**
```
slope = REGR_SLOPE(metric_avg, day_epoch) over 30-day window
degradation_trend = positive_slope_magnitude
```

---

## ðŸ“Š Metric Tier Classification

### Tier-1 (Primary CFRS Drivers)
**Use Case Independent** - Critical degradation indicators

| Metric | Description | CFRS Relevance |
|--------|-------------|----------------|
| `cpu_iowait_percent` | CPU time waiting for I/O | Storage/network bottleneck |
| `context_switch_rate` | Context switches per second | System thrashing indicator |
| `swap_out_rate` | Memory pages swapped out/sec | Memory pressure critical |
| `major_page_fault_rate` | Major page faults/sec | Storage latency spike |
| `cpu_temperature` | CPU thermal reading (Â°C) | Thermal stress/cooling failure |
| `gpu_temperature` | GPU thermal reading (Â°C) | GPU cooling degradation |

### Tier-2 (Secondary CFRS Contributors)
**Context-Dependent** - Important but less universally critical

| Metric | Description | CFRS Relevance |
|--------|-------------|----------------|
| `cpu_percent` | Overall CPU utilization | Workload baseline |
| `ram_percent` | Memory utilization | Capacity planning |
| `disk_percent` | Disk space utilization | Storage exhaustion risk |
| `swap_in_rate` | Memory pages swapped in/sec | Memory reclaim activity |
| `page_fault_rate` | Minor page faults/sec | Memory access patterns |

---

## ðŸ—„ï¸ Database Schema Overview

### 1. Continuous Aggregates

#### `cfrs_hourly_stats`
**Purpose:** Hourly statistical derivatives for Deviation + Variance components

**Columns per Metric:**
- `avg_{metric}` - Mean value (for z-score baseline)
- `stddev_{metric}` - Standard deviation (variance component)
- `p95_{metric}` - 95th percentile (alternative deviation baseline)
- `cnt_{metric}` - Non-NULL count (sample quality indicator)

**Refresh Policy:** Every hour, covering last 3 hours

**Example Query:**
```sql
SELECT
    system_id,
    hour_bucket,
    avg_cpu_iowait,
    stddev_cpu_iowait,
    p95_cpu_iowait,
    cnt_cpu_iowait
FROM cfrs_hourly_stats
WHERE system_id = 42
  AND hour_bucket >= NOW() - INTERVAL '24 hours'
ORDER BY hour_bucket DESC;
```

#### `cfrs_daily_stats`
**Purpose:** Daily statistical derivatives for Trend component

**Columns per Metric:**
- `avg_{metric}` - Daily mean (for regression)
- `stddev_{metric}` - Daily standard deviation
- `cnt_{metric}` - Non-NULL count

**Refresh Policy:** Daily, covering last 3 days

**Example Query:**
```sql
SELECT
    system_id,
    day_bucket,
    avg_cpu_iowait,
    stddev_cpu_iowait
FROM cfrs_daily_stats
WHERE system_id = 42
  AND day_bucket >= NOW() - INTERVAL '30 days'
ORDER BY day_bucket;
```

### 2. Baseline Storage

#### `cfrs_system_baselines`
**Purpose:** Store expected behavior statistics for deviation normalization

**Schema:**
```sql
CREATE TABLE cfrs_system_baselines (
    baseline_id SERIAL PRIMARY KEY,
    system_id INT NOT NULL,
    metric_name VARCHAR(50) NOT NULL,
    
    -- Baseline statistics
    baseline_mean NUMERIC(12,4) NOT NULL,
    baseline_stddev NUMERIC(12,4),
    baseline_mad NUMERIC(12,4),
    baseline_median NUMERIC(12,4),
    
    -- Context
    baseline_window_days INT NOT NULL,
    baseline_start TIMESTAMPTZ NOT NULL,
    baseline_end TIMESTAMPTZ NOT NULL,
    sample_count INT NOT NULL,
    
    -- Metadata
    computed_at TIMESTAMPTZ DEFAULT NOW(),
    is_active BOOLEAN DEFAULT TRUE
);
```

**Usage Pattern:**
1. External script computes baseline statistics (e.g., 30-day averages during "normal" operation)
2. Insert into this table
3. CFRS engine joins current metrics with baselines to compute z-scores

**Example Baseline Computation:**
```sql
-- Compute 30-day baseline for cpu_iowait on system 42
INSERT INTO cfrs_system_baselines (
    system_id, metric_name,
    baseline_mean, baseline_stddev, baseline_median,
    baseline_window_days, baseline_start, baseline_end, sample_count
)
SELECT
    42 AS system_id,
    'cpu_iowait' AS metric_name,
    AVG(avg_cpu_iowait) AS baseline_mean,
    STDDEV(avg_cpu_iowait) AS baseline_stddev,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY avg_cpu_iowait) AS baseline_median,
    30 AS baseline_window_days,
    MIN(hour_bucket) AS baseline_start,
    MAX(hour_bucket) AS baseline_end,
    COUNT(*) AS sample_count
FROM cfrs_hourly_stats
WHERE system_id = 42
  AND hour_bucket >= NOW() - INTERVAL '30 days'
  AND avg_cpu_iowait IS NOT NULL;
```

### 3. Trend Views

#### `v_cfrs_daily_tier1_trends`
**Purpose:** Daily Tier-1 metrics ready for linear regression

**Key Feature:** Includes `day_epoch` column (Unix timestamp) for regression X-axis

**Example Slope Computation (External):**
```sql
-- Compute 30-day slope for CPU I/O wait
SELECT
    system_id,
    REGR_SLOPE(avg_cpu_iowait, day_epoch) AS cpu_iowait_slope,
    REGR_R2(avg_cpu_iowait, day_epoch) AS slope_r2,
    COUNT(*) AS days_in_window
FROM v_cfrs_daily_tier1_trends
WHERE day_bucket >= NOW() - INTERVAL '30 days'
  AND avg_cpu_iowait IS NOT NULL
GROUP BY system_id
HAVING COUNT(*) >= 20;  -- Require 20+ days for reliable trend
```

**Interpretation:**
- `slope > 0` = Metric worsening over time (degradation)
- `slope < 0` = Metric improving over time
- `r2 > 0.7` = Strong linear trend (high confidence)

#### `v_cfrs_weekly_tier1_trends`
**Purpose:** 7-day rolling aggregates for medium-term pattern detection

**Use Case:** Detect multi-day degradation patterns that daily aggregates might miss

---

## ðŸ”¢ Statistical Properties

### NULL Handling

**Critical:** All aggregates are NULL-safe. COUNT(metric) excludes NULLs.

**Why This Matters:**
- Not all systems have all sensors (e.g., some lack GPUs)
- Collector failures create gaps
- Zero is meaningful; NULL is absence of data

**Example:**
```sql
-- System with no GPU â†’ gpu_temperature is NULL
-- avg_gpu_temp will be NULL (not 0)
-- cnt_gpu_temp will be 0 (not total_samples)
```

### Sample Quality Indicators

Every aggregate includes:
- `cnt_{metric}` - Number of non-NULL samples
- `total_samples` - Total rows in bucket

**Usage:**
```sql
-- Only use aggregates with sufficient samples
SELECT * FROM cfrs_hourly_stats
WHERE cnt_cpu_iowait >= 10  -- At least 10 non-NULL samples
  AND cnt_cpu_iowait::FLOAT / total_samples >= 0.8;  -- 80%+ coverage
```

### No Fixed Interval Assumptions

**Problem with naive aggregates:**
```sql
-- WRONG: Assumes exactly 12 samples per hour (5-min intervals)
SELECT COUNT(*) * 5 AS minutes_above_threshold ...
```

**CFRS-compliant approach:**
```sql
-- CORRECT: Uses actual sample counts
SELECT
    cnt_cpu_iowait,  -- Actual non-NULL samples
    total_samples,   -- Actual rows in bucket
    cnt_cpu_iowait::FLOAT / NULLIF(total_samples, 0) AS coverage_ratio
FROM cfrs_hourly_stats;
```

---

## ðŸ”§ Deployment Guide

### Initial Setup (New Database)

```bash
# 1. Create database and enable TimescaleDB
psql -d postgres -c "CREATE DATABASE optilab_cfrs;"
psql -d optilab_cfrs -c "CREATE EXTENSION timescaledb;"

# 2. Create base schema (systems, metrics tables)
psql -d optilab_cfrs -f database/schema.sql

# 3. Setup hypertable
psql -d optilab_cfrs -c "SELECT create_hypertable('metrics', 'timestamp', if_not_exists => TRUE);"

# 4. Deploy CFRS layer
psql -d optilab_cfrs -f database/cfrs_timescale_layer.sql

# 5. Verify
psql -d optilab_cfrs -c "SELECT * FROM timescaledb_information.continuous_aggregates;"
```

### Migration (Existing Database)

```bash
# 1. Backup first!
pg_dump -d optilab_mvp > backup_$(date +%Y%m%d).sql

# 2. Run migration script
psql -d optilab_mvp -f database/migrate_to_cfrs_layer.sql

# 3. Verify aggregates populated
psql -d optilab_mvp -c "SELECT COUNT(*) FROM cfrs_hourly_stats;"
psql -d optilab_mvp -c "SELECT COUNT(*) FROM cfrs_daily_stats;"
```

### Post-Deployment Tasks

1. **Populate Baselines**
   ```bash
   # Run baseline computation for all systems
   python scripts/compute_initial_baselines.py
   ```

2. **Monitor Aggregate Freshness**
   ```sql
   SELECT
       view_name,
       refresh_lag,
       last_run_duration,
       last_run_status
   FROM timescaledb_information.continuous_aggregate_stats
   WHERE view_name LIKE 'cfrs_%';
   ```

3. **Configure CFRS Engine**
   - Update connection strings to query `cfrs_hourly_stats` and `cfrs_daily_stats`
   - Implement z-score computation using `cfrs_system_baselines`
   - Implement regression-based trend analysis using `v_cfrs_daily_tier1_trends`

---

## ðŸ” Query Patterns

### Pattern 1: Retrieve All CFRS Inputs for One System

```sql
-- Get last 24 hours of CFRS-relevant data
SELECT
    h.hour_bucket,
    
    -- Tier-1 metrics (primary CFRS drivers)
    h.avg_cpu_iowait,
    h.stddev_cpu_iowait,
    h.p95_cpu_iowait,
    h.avg_context_switch,
    h.stddev_context_switch,
    h.avg_swap_out,
    h.stddev_swap_out,
    h.avg_major_page_faults,
    h.stddev_major_page_faults,
    h.avg_cpu_temp,
    h.stddev_cpu_temp,
    h.avg_gpu_temp,
    h.stddev_gpu_temp,
    
    -- Sample quality
    h.cnt_cpu_iowait,
    h.total_samples

FROM cfrs_hourly_stats h
WHERE h.system_id = 42
  AND h.hour_bucket >= NOW() - INTERVAL '24 hours'
ORDER BY h.hour_bucket DESC;
```

### Pattern 2: Compute Z-Scores (Deviation Component)

```sql
-- Join current stats with baselines
SELECT
    h.system_id,
    h.hour_bucket,
    h.avg_cpu_iowait AS current_value,
    b.baseline_mean,
    b.baseline_stddev,
    
    -- Z-score computation (do this in application, not SQL)
    -- z = (current - mean) / stddev
    -- But if you must do it in SQL:
    CASE
        WHEN b.baseline_stddev > 0 THEN
            (h.avg_cpu_iowait - b.baseline_mean) / b.baseline_stddev
        ELSE NULL
    END AS z_score

FROM cfrs_hourly_stats h
JOIN cfrs_system_baselines b
    ON h.system_id = b.system_id
   AND b.metric_name = 'cpu_iowait'
   AND b.is_active = TRUE
WHERE h.hour_bucket >= NOW() - INTERVAL '24 hours'
ORDER BY ABS(
    (h.avg_cpu_iowait - b.baseline_mean) / NULLIF(b.baseline_stddev, 0)
) DESC NULLS LAST
LIMIT 10;  -- Top 10 most deviant hours
```

### Pattern 3: Detect Degradation Trends (Trend Component)

```sql
-- 30-day trend analysis for all systems
WITH trend_analysis AS (
    SELECT
        system_id,
        REGR_SLOPE(avg_cpu_iowait, day_epoch) AS cpu_iowait_slope,
        REGR_R2(avg_cpu_iowait, day_epoch) AS cpu_iowait_r2,
        REGR_SLOPE(avg_major_page_faults, day_epoch) AS page_fault_slope,
        REGR_R2(avg_major_page_faults, day_epoch) AS page_fault_r2,
        COUNT(*) AS days_with_data
    FROM v_cfrs_daily_tier1_trends
    WHERE day_bucket >= NOW() - INTERVAL '30 days'
      AND avg_cpu_iowait IS NOT NULL
    GROUP BY system_id
    HAVING COUNT(*) >= 20  -- At least 20 days of data
)
SELECT
    s.hostname,
    t.cpu_iowait_slope,
    t.cpu_iowait_r2,
    t.page_fault_slope,
    t.page_fault_r2,
    t.days_with_data,
    
    -- Interpretation flags
    CASE
        WHEN t.cpu_iowait_slope > 0.1 AND t.cpu_iowait_r2 > 0.7 THEN 'DEGRADING'
        WHEN t.cpu_iowait_slope < -0.1 AND t.cpu_iowait_r2 > 0.7 THEN 'IMPROVING'
        ELSE 'STABLE'
    END AS trend_status

FROM trend_analysis t
JOIN systems s ON t.system_id = s.system_id
ORDER BY t.cpu_iowait_slope DESC;
```

### Pattern 4: Multi-Metric Variance Analysis

```sql
-- Identify systems with high volatility across multiple metrics
SELECT
    system_id,
    hour_bucket,
    
    -- Coefficient of variation (stddev / mean) for key metrics
    CASE WHEN avg_cpu_iowait > 0 THEN
        stddev_cpu_iowait / avg_cpu_iowait
    END AS cv_cpu_iowait,
    
    CASE WHEN avg_context_switch > 0 THEN
        stddev_context_switch / avg_context_switch
    END AS cv_context_switch,
    
    CASE WHEN avg_swap_out > 0 THEN
        stddev_swap_out / avg_swap_out
    END AS cv_swap_out,
    
    -- Aggregate volatility score (count of high-CV metrics)
    (
        (CASE WHEN stddev_cpu_iowait / NULLIF(avg_cpu_iowait, 0) > 0.5 THEN 1 ELSE 0 END) +
        (CASE WHEN stddev_context_switch / NULLIF(avg_context_switch, 0) > 0.5 THEN 1 ELSE 0 END) +
        (CASE WHEN stddev_swap_out / NULLIF(avg_swap_out, 0) > 0.5 THEN 1 ELSE 0 END)
    ) AS high_volatility_count

FROM cfrs_hourly_stats
WHERE hour_bucket >= NOW() - INTERVAL '24 hours'
  AND total_samples >= 10
ORDER BY high_volatility_count DESC, hour_bucket DESC
LIMIT 50;
```

---

## ðŸ“ˆ Performance Characteristics

### Query Performance

| Operation | Without Aggregates | With CFRS Aggregates | Speedup |
|-----------|-------------------|----------------------|---------|
| 24-hour average | ~500ms (scan 288 rows Ã— 100 systems) | ~20ms (scan 24 rows Ã— 100 systems) | **25x** |
| 30-day trends | ~5s (scan 8,640 rows Ã— 100 systems) | ~150ms (scan 30 rows Ã— 100 systems) | **33x** |
| Multi-system queries | ~30s (full table scan) | ~1s (aggregate scan) | **30x** |

### Storage Efficiency

**Assumptions:** 100 systems, 5-minute sampling, 30-day retention

| Component | Raw Rows | Aggregate Rows | Compression Ratio | Storage Saved |
|-----------|----------|----------------|-------------------|---------------|
| Raw metrics | 8,640,000 | N/A | ~10:1 (TimescaleDB) | Baseline |
| Hourly aggregates | N/A | 72,000 | N/A | 99%+ reduction |
| Daily aggregates | N/A | 3,000 | N/A | 99.96%+ reduction |

**Total Storage (30 days, 100 systems):**
- Raw metrics: ~2.5 GB (compressed)
- Hourly aggregates: ~150 MB
- Daily aggregates: ~10 MB
- **Total: ~2.7 GB** (vs. ~25 GB uncompressed)

---

## ðŸ›¡ï¸ Data Quality Guarantees

### 1. Monotonic Time Buckets
- Time buckets never overlap
- Aggregates are deterministic (same result on re-refresh)

### 2. NULL Semantics
- `AVG(metric)` ignores NULLs (correct behavior)
- `COUNT(metric)` counts non-NULLs only
- `STDDEV(metric)` requires â‰¥2 non-NULL values

### 3. Referential Integrity
- All `system_id` references exist in `systems` table
- Baseline table enforces `baseline_end > baseline_start`
- Baseline table enforces `sample_count > 0`

### 4. Idempotency
- All DDL scripts use `IF NOT EXISTS`
- Safe to run migration multiple times
- Refresh operations are idempotent

---

## ðŸš¨ Monitoring & Alerts

### Critical Metrics to Monitor

1. **Aggregate Freshness**
   ```sql
   SELECT
       view_name,
       refresh_lag,
       last_run_status
   FROM timescaledb_information.continuous_aggregate_stats
   WHERE view_name LIKE 'cfrs_%'
     AND (refresh_lag > INTERVAL '2 hours' OR last_run_status != 'Success');
   ```
   **Alert:** Lag > 2 hours or failed refresh

2. **Baseline Coverage**
   ```sql
   SELECT
       COUNT(DISTINCT system_id) AS systems_with_baselines,
       (SELECT COUNT(*) FROM systems WHERE status = 'active') AS total_active_systems
   FROM cfrs_system_baselines
   WHERE is_active = TRUE;
   ```
   **Alert:** Coverage < 90% of active systems

3. **Sample Quality**
   ```sql
   SELECT
       system_id,
       COUNT(*) AS hours_with_low_samples
   FROM cfrs_hourly_stats
   WHERE hour_bucket >= NOW() - INTERVAL '24 hours'
     AND total_samples < 10
   GROUP BY system_id
   HAVING COUNT(*) > 5;
   ```
   **Alert:** >5 hours with <10 samples in last 24h

---

## ðŸ” Security Considerations

### Read-Only CFRS Engine User

```sql
-- Create role for CFRS computation engine
CREATE ROLE cfrs_engine LOGIN PASSWORD 'secure_password';

-- Grant read access to CFRS views only
GRANT CONNECT ON DATABASE optilab_cfrs TO cfrs_engine;
GRANT USAGE ON SCHEMA public TO cfrs_engine;
GRANT SELECT ON cfrs_hourly_stats TO cfrs_engine;
GRANT SELECT ON cfrs_daily_stats TO cfrs_engine;
GRANT SELECT ON cfrs_system_baselines TO cfrs_engine;
GRANT SELECT ON v_cfrs_daily_tier1_trends TO cfrs_engine;
GRANT SELECT ON v_cfrs_daily_tier2_trends TO cfrs_engine;
GRANT SELECT ON v_cfrs_weekly_tier1_trends TO cfrs_engine;

-- Explicitly deny write access
REVOKE INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public FROM cfrs_engine;
```

---

## ðŸ“š References

### Related Documents
- [CFRS_IMPLEMENTATION_SUMMARY.md](CFRS_IMPLEMENTATION_SUMMARY.md) - Quick reference
- [CFRS_METRICS_IMPLEMENTATION.md](CFRS_METRICS_IMPLEMENTATION.md) - Advanced metrics details
- [database/cfrs_timescale_layer.sql](cfrs_timescale_layer.sql) - Complete SQL implementation

### Academic Foundation
- **Deviation Component:** Z-score normalization (standard statistical technique)
- **Variance Component:** Coefficient of variation, STDDEV analysis
- **Trend Component:** Linear regression, time-series slope analysis

### TimescaleDB Documentation
- [Continuous Aggregates](https://docs.timescale.com/timescaledb/latest/how-to-guides/continuous-aggregates/)
- [Compression](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/)
- [Retention Policies](https://docs.timescale.com/timescaledb/latest/how-to-guides/data-retention/)

---

## ðŸ†˜ Troubleshooting

### Issue: Aggregates Not Refreshing

**Symptoms:** `refresh_lag` increasing, no new data in aggregates

**Solution:**
```sql
-- Check background worker jobs
SELECT * FROM timescaledb_information.jobs
WHERE proc_name LIKE '%continuous_aggregate%';

-- Manually refresh
CALL refresh_continuous_aggregate('cfrs_hourly_stats', NULL, NULL);
```

### Issue: High Query Latency

**Symptoms:** CFRS queries taking >5 seconds

**Solution:**
```sql
-- Ensure aggregates are being used
EXPLAIN ANALYZE
SELECT * FROM cfrs_hourly_stats
WHERE hour_bucket >= NOW() - INTERVAL '24 hours';

-- Should show "Seq Scan on _materialized_hypertable_X"
-- NOT "Seq Scan on metrics"
```

### Issue: Missing Baselines

**Symptoms:** Z-score computation fails, no baselines for systems

**Solution:**
```sql
-- Check which systems lack baselines
SELECT s.system_id, s.hostname
FROM systems s
LEFT JOIN cfrs_system_baselines b
    ON s.system_id = b.system_id AND b.is_active = TRUE
WHERE b.baseline_id IS NULL
  AND s.status = 'active';

-- Run baseline computation script for missing systems
-- python scripts/compute_baselines.py --system-id 42
```

---

## âœ… Validation Checklist

Before deploying to production:

- [ ] All continuous aggregates created successfully
- [ ] Refresh policies configured (check `timescaledb_information.jobs`)
- [ ] Aggregates contain data (`SELECT COUNT(*) FROM cfrs_hourly_stats;`)
- [ ] Baselines populated for all active systems
- [ ] Trend views return data
- [ ] CFRS engine can connect with read-only credentials
- [ ] Monitoring alerts configured for aggregate freshness
- [ ] Backup and rollback plan documented

---

## ðŸ“ž Support

For questions or issues:
1. Check [CFRS_IMPLEMENTATION_SUMMARY.md](CFRS_IMPLEMENTATION_SUMMARY.md) for quick answers
2. Review [database/cfrs_timescale_layer.sql](cfrs_timescale_layer.sql) for implementation details
3. Consult TimescaleDB documentation for database-specific issues

---

**Document Version:** 1.0  
**Last Updated:** 2026-01-28  
**Maintainer:** OptiLab CFRS Team
